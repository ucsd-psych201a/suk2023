---
title: "Replication of Study 2 from Effects of donation collection methods on donation amount: Nudging donation for the cause and overhead by Suk & Mudita (2022, Psychology & Marketing)"
author: "William de Melo (wdemelo@ucsd.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

## Introduction

Charity organizations rely on donations to both support their advertised cause and maintain their overhead expenses. However, donors support charities less when they think their donations are used more for overheads than for a cause, a heuristic known as *overhead aversion.* In their paper, *Effects of donation collection methods on donation amount: Nudging donation for the cause and overhead*, Drs. Kwanho Suk and Triza Mudita contribute to research on reducing/adapting to overhead aversion. They do this by administering a series of experiments with which they assess the affects of choice architecture on participants' willingness to donate to charity.

In the second of their three documented experiments, Suk and Mudita found that participants give more money when asked to donate to a charity's overhead expenses first, before being asked to donate to its causes, as opposed to cause first, overheads second. Based on this finding, charity organizations could get more money to achieve their goals simply by changing the order in which donations are asked for. We therefore replicate Suk and Mudita's experiment in this replication to assess the reliability of their data.

## Methods

### Power Analysis

Using G\*power, we conducted an a priori power analysis of the original finding that the total amount donated by participants was greater for those in the overhead first condition as opposed to the cause first condition. Our power analysis assumed a t-test for two independent means. Using the finding's effect size (*d* = .41) yielded an estimate of 188 participants needed to replicate this finding with a statistical power of .8.

### Planned Sample

We aim to collect data from at least 188 participants through Prolific, as per our power analysis, to assure we have at least 94 participants in each of our two conditions. Our plan is to terminate data collection once this minimum is met. Although the majority of participants from the original study came from the UK, we do not control for nationality, or any other demographic variables.

### Materials

In order to conduct this experiment, we create a custom website using js-Psych to administer a website like the one Suk and Mudita devised. We start with a 10-question unrelated survey that asks participants about various habits, such as their sleep patterns, hobbies, and daily lives. This survey functions as a cover story; once participants complete it, they progress to the real experiment under the premise that they have completed the bulk of the work, making our actual manipulation seem more like an add-on. This will reduce demand characteristics, as our participants will not treat the actual experiment as something the researchers are looking for answers to.

We follow the example set by Appendix C from the original study to create two experimental conditions, cause first and overhead first. The first item in the cause first condition will read, "For the cause:" and have a text box where participants can fill in the amount they want to donate to the charity's cause. The second item will read, "For covering charitable organization's operating expenses," and have a text box as well. Below those boxes will be an item reading "Total," listing the sum total of both of the participants' inputs. All values are indicated in US dollars. For the overheads first condition, the order of the first two items is reversed.

After they confirm their total donation, we also ask participants to indicate their agreement with two questions, "I am satisfied with my donation," and "I usually donate to charity." These items are answered by inputting values on a 7-point Likert scale (1 indicating "not at all," 7 indicating "very much"). These values will be independent variables in a series of regression analyses conducted after data collection.

### Procedure

Our procedure mirrors that of the original study. At the start of our experiment, we ask for participants' consent. We then administer our unrelated survey. After completing the survey, participants move on to the experiment, and are informed they have a 20% chance to earn 8 USD upon completion. To ensure participants understand this, we administer a comprehension check here.

We then inform participants of the way charity organizations use donations to both support their cause and to maintain their operation expenses. We also inform participants that some charities receive these two kinds of donations separately. As the last part of the information portion of our experiment, we tell participants they have the opportunity, provided they win the extra 8 dollars, to give to a non-specific donation campaign for children born with disabilities in an Asian country. This is followed by another comprehension check to assess whether our participants understood what they had been told.

Upon reading through the relevant information, participants will be randomly assigned into either the cause first or overhead first condition. In each condition, all participants are given the opportunity to donate some, all, or none of the 8 dollars they stand to gain by completing this experiment to the donation campaign. Depending on which condition they are placed in, they will be asked to provide the amount they want to donate to the cause first, before being able to indicate the amount they want to donate to the overheads, or vice-versa.

Regardless of condition, participants will be able to confirm the total amount of money they would be donating to both the cause and the overhead expenses. Participants are reminded that they can donate as much as they want so long as their total does not exceed 8 USD, and that they can also choose to keep the full amount. Then, participants are asked to rate their satisfaction with their donation, as well as how often they donate to charity, on Likert scales from 1 to 7. At the very end of our survey, we ask participants to indicate their age, gender, and nationality before debriefing.

Upon having collected data from at least 94 participants in each condition, we will randomly select 20% of our participants to earn 8 USD (around 38 out of at least 188 participants). In accordance with what they said they would donate if they earned the 8 dollars, we will donate the amount they specified to a real charity organization, World Vision, and send them the remainder.

### Analysis Plan

A series of tests will be administered to our data to match those conducted in the original experiment. First, we conduct a regression analysis to determine whether any of the data we have recorded can explain the variation within the total amount donated by participants. Then, we conduct two separate regression analyses to determine the impact of these factors on amounts donated to our charity's cause and overheads specifically.

We then utilize our participants' self-reported satisfaction in a second round of tests. We perform a regression analysis using condition as an independent variable and satisfaction as a dependent variable to see if the order in which donations are asked for affects donor sentiment. We then add demographic variables as independent variables for another regression analysis, and the amounts donated in each condition for causes and overheads in a third in order to assess interactions among all of our variables.

### Differences from Original Study

The majority of the original study's participants were from the UK, so the bonus incentive offered for completing the experiment was 6 pounds. However, we do not control for nationality in our study, so we expect most of our participants to be American. Therefore, we round up from the conversion of 6 pounds to 7.72 dollars to an 8 dollar compensation for 20% of our participants.

### Design Overview

Only one factor was manipulated, that being the order in which participants were asked to donate to the cause and overheads of the charity. Four measures are taken, the donation to the cause, the donation to the overheads, participants' satisfaction with their donation, and participants' frequency with which they donate. Additional variables, like age, gender, and nationality, are also recorded.

This study employs a between-participants design; participants may only supply data in one condition of our experiment. No measures are repeated. It should also be said that this experiment could not have been done as a within-participants experiment. If we were to use a within-participants design, we would be asking participants to donate to the same charity twice in 8 dollar increments. This raises concerns with demand characteristics, as it makes what we're testing for more obvious. We could change this by asking participants to donate to two different charities, but that would introduce the potential confound that participants might prefer one charity to the other. Therefore, this experiment must be between-participants.

\
Like in the original study, an unrelated survey is administered before the actual experiment, and the actual experiment is treated as an add-on. This reduces demand characteristics because it frames the actual experiment as something separate from what the participants *think* the study is. Because the participants aren't treating the actual experiment as part of the survey, they aren't thinking about what the experimenters want to see. Therefore, the unrelated survey functions as a kind of cover story which protects from demand characteristics.

One potential confound of our study is the order in which participants are informed about the causes and overheads of charities. This experiment is specifically testing the effect of order on donations; it stands to reason that the order in which we inform participants about how charities work may affect our manipulation. For instance, if we describe how charities need donations for their overhead expenses *before* we describe how charities need donations to support their cause, participants may see donating to the overhead expenses as more important, affecting their responses.

Though this study has interesting findings, there are limits to its generalization to real-life situations. Would people actually donate more to charities that put their overheads first and cause second when asking for donations? It is a difficult inference because in real situations, participants do not stand to gain any money like they are with this study. Some people would probably be fine with donating 4 dollars to charity if they were also receiving 4 dollars, but not if they had to donate entirely from their own pockets, receiving no compensation in return.

Additionally, participants cannot donate more than 8 dollars in this study, but in real life, there is no limit to how much one could donate. The constraints within the experiment are comfortable for participants to think about because there is a clear range for which their donation can fall under. But in real life, where one does not have this limit, it is more difficult to decide how much to donate, which can lead to not donating at all due to choice paralysis.

Lastly, participants are asked to provide how much they would donate *based on the assumption* that they would be one of the lucky 20% to earn 8 dollars at the end of the study. Participants may not be taking their answers seriously because they expect to be one of the 80% that earns nothing. At those odds, participants may be more generous than they normally are because they see proving to *themselves* that they are generous as more valuable than the slim chance of earning 8 dollars.

### Methods Addendum (Post Data Collection)

#### Actual Sample

#### Differences from pre-data collection methods plan

## Results

### Data Preparation

Using jsPsych, we establish a pipeline from our custom website to an OSF database that populates in .csv format as results come in. We will monitor this data continually, filtering out participants that fail the confirmation checks, until we ensure that we have 94 valid participants in each condition.

#### Load Relevant Libraries and Functions

For our data cleaning and analyses, we need tidyverse, which is necessary for reading, cleaning, and analyzing .csv data. Additionally, jsonlite will assist in converting the raw output from the datapipe into a usable format.

```         
library(jsonlite)
library(tidyverse)
```

We utilize the following functions in our analysis:

```         
## For data formatting

read_csv()
subset()
data.frame()
mutate()
lapply()
sapply()
tryCatch()
fromJSON()
unnest_wider()
bind_rows()
write_csv()

## For removing JSON formatting

mutate()
recode()
gsub()

## For analyses

lm()
summary()
group_by()
summarize()
```

#### Import data

We import the data to R using the tidyverse library's read_csv() function, after having downloaded the data from our OSF database.

```         
file_paths <- c(
                "/Users/willdemelo/Downloads/drddd9wdeu.csv",
                "/Users/willdemelo/Downloads/omw1tq4sk4.csv",
                ...
                )
```

#### Data exclusion / filtering

If participants fail both of the confirmation checks we administer before they list how much money they would donate, their results will be excluded from the study. We may also exclude results if they enter non-serious answers for demographic variables or other inputs.

#### Prepare data for analysis - create columns etc.

The datapipe for our experiment fills our OSF database with individual .csv files for each of our participants' inputs. This function is designed to take the messy, haphazard outputs from each .csv file and turn them into a row with columns for comprehension checks, the amounts donated for which purposes, which condition the participant was exposed to, and other variables. Then, these individual rows are joined to create a single .csv file.

```         
process_csv_files <- function(file_paths, output_file) {
  
  # Nested function to process a single file
  process_file <- function(file_path) {
    
    # Reads file
    testdata <- read_csv(file_path)
    
    # Shortens file to specified columns
    tdcols <- subset(testdata, select = -c(rt, stimulus, trial_type, plugin_version, question_order))
    
    # Shortens file to specified rows
    tdrows <- tdcols[-c(1:13, 16:17), , drop = FALSE]
    
    # Rearranges elements of cleaned data into one cohesive row
    tdarrange <- data.frame(
      check1 = tdrows$response[1],
      check2 = tdrows$response[2],
      cause = tdrows$causeDonation[3],
      overhead = tdrows$expenseDonation[3],
      total = tdrows$totalDonation[3],
      condition = tdrows$questionOrder[3],
      satis_usual = tdrows$response[4],
      age = tdrows$age[5],
      nationality = tdrows$nationality[5],
      gender = tdrows$response[6],
      comment = tdrows$response[7]
    )
    
    # Parses the satisfaction responses, unnests JSON formatting
    tdparsed <- tdarrange %>%
      mutate(satis_usual = lapply(satis_usual, function(x) {
        tryCatch(fromJSON(x), error = function(e) NA)
        }))
    
    # Unnests the satisfaction/frequency column into two separate columns
    tdsep <- tdparsed %>%
      unnest_wider(col = satis_usual, names_sep = "_")
    
    # Renames columns
    tdclean <- tdsep %>% 
      rename(satisfaction = satis_usual_Q0,
             frequency = satis_usual_Q1)
    
    # Returns cleaned data
    return(tdclean)
  }
  
  # Apply nested function to each file
  processed_files <- lapply(file_paths, process_file)
  
  # Combines files, adds identifying number
  all_data <- bind_rows(processed_files, .id = "file_id")
  
  # Saves the combined data
  write_csv(all_data, output_file)
  
  # Returns combined data
  return(all_data)
}
```

This .csv file is further cleaned through a series of steps designed to remove all traces of JSON formatting from the data. Additionally, variables are renamed for ease of comprehension and analysis.

```         
## Cleans JSON formatting
# Function removes all of the special charcters from the data
remove_special_characters <- function(entry) {
  gsub("[^a-zA-Z0-9\\s]", "", entry)
}

# Applies function to all relevant columns
cleanresult <- result %>%
  mutate(check1 = sapply(check1, remove_special_characters)) %>% 
  mutate(check2 = sapply(check2, remove_special_characters)) %>% 
  mutate(condition = sapply(condition, remove_special_characters)) %>% 
  mutate(gender = sapply(gender, remove_special_characters)) %>% 
  mutate(comment = sapply(comment, remove_special_characters))

# Edits data for legibility
cleanresult <- cleanresult %>%
  mutate(
    condition = recode(
      condition,
      ForthecauseForcoveringcharitableorganizationsoperatingexpense = 'causefirst',
      ForcoveringcharitableorganizationsoperatingexpenseForthecause = 'overfirst'
    ),
    check1 = gsub("chanceresponse", "", check1),
    check2 = gsub("donationuseresponse", "", check2),
    gender = gsub("gender", "", gender),
    comment = gsub("Q0", "", comment)
  )
```

### Confirmatory analysis

To confirm our prepearations for analysis work, we conduct a regression analysis to determine the statistical significance of the independent variables we have collected on the total amounts donated.

```         
output <- lm('total ~ condition + satisfaction + frequency + age + nationality + gender', data = cleanresult)
summary(output)
```

With 16 data points from our pilot study, we produce this output, ensuring our pipelines and formatting work as intended.

```         
Residuals:
         1          2          3          4          5          6          7          8          9         10 
-9.000e-01  4.500e+00 -1.416e-15  3.469e-15 -5.274e-16  1.800e+00 -2.700e+00  2.776e-17 -3.053e-16 -7.494e-16 
        11         12         13         14         15         16 
 4.718e-16 -2.700e+00  9.000e-01 -9.000e-01 -1.193e-15  2.498e-16 

Coefficients: (2 not defined because of singularities)
                     Estimate Std. Error t value Pr(>|t|)
(Intercept)          -74.1615   198.5821  -0.373    0.772
conditionoverfirst     0.5615     8.6278   0.065    0.959
satisfaction          -2.6731     9.5035  -0.281    0.825
frequency             -3.4385    10.5156  -0.327    0.799
age                    0.5692     1.4751   0.386    0.766
nationalityAmer       78.5038   206.9366   0.379    0.769
nationalityAmerican   74.6923   198.6855   0.376    0.771
nationalityAsian      91.0500   233.1586   0.391    0.763
nationalityChina      79.9846   224.5383   0.356    0.782
nationalityChinese    88.3346   234.0679   0.377    0.770
nationalitycongolese  88.0423   238.4819   0.369    0.775
nationalityIndian     97.7231   259.7963   0.376    0.771
nationalityJapanese   85.7000   224.0060   0.383    0.767
genderMale             2.1231     5.5747   0.381    0.768
genderNonbinary        0.5077    15.6688   0.032    0.979
genderOther                NA         NA      NA       NA
genderPrefernottosay       NA         NA      NA       NA

Residual standard error: 6.364 on 1 degrees of freedom
Multiple R-squared:  0.7888,    Adjusted R-squared:  -2.168 
F-statistic: 0.2668 on 14 and 1 DF,  p-value: 0.9267
```

From this analysis, we can see that none of our variables have a significant relationship with total donation. We then calculate Cohen's d:\

```         
outputmean <- cleanresult %>% group_by(condition) %>%  summarize(mean = mean(total))
outputsd <- cleanresult %>% summarize(sd = sd(total))
CohensD <- (outputmean$mean[1] - outputmean$mean[2])/outputsd$sd[1]
```

Our Cohen's D was .5483, indicating a medium effect size. The means of the total donations among the cause first and overheads first conditions are 5.8889 and 3.9286, respectively. The standard deviation of total donations among both conditions is 3.5754. From our pilot sample, we observe the opposite effect as what the original study found, but this is likely due to our poor sample size. More accurate results will be obtained from our real sample.

\
Our data on the Open Science Framework is stored here:

<https://osf.io/jzx7e/>

Our survey can be taken here:

<https://ucsd-psych201a.github.io/suk2023/website/>

The HTML code for the survey can be seen here:

<https://github.com/ucsd-psych201a/suk2023/blob/main/website/index.html>

Pilot data can be found here:

<https://github.com/ucsd-psych201a/suk2023/blob/main/data/pilotdata.csv>

Link to repository:

<https://github.com/ucsd-psych201a/suk2023>

*End of progress as of November 11th*

### Exploratory analyses

Any follow-up analyses desired (not required).

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt. None of these need to be long.
